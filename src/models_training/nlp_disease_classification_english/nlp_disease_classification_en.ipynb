{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la carpeta actual\n",
    "current_dir = Path.cwd()\n",
    "DATASETS_LOCATION = os.path.join(current_dir.parent.parent.parent, 'datasets')\n",
    "MODELS_LOCATION = os.path.join(current_dir.parent.parent, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been feeling tired all the time and notic...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lately, Ive been out of breath even after lig...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the past few weeks, Ive been extremely we...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms Disease\n",
       "0  I've been feeling tired all the time and notic...  Anemia\n",
       "1  Lately, Ive been out of breath even after lig...  Anemia\n",
       "2  For the past few weeks, Ive been extremely we...  Anemia"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disease_sp = pd.read_excel(os.path.join(DATASETS_LOCATION, 'disease_nlp_eng.xlsx'))\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "df_disease_sp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Disease English antes de undersampling:\n",
      "Disease\n",
      "Anemia         100\n",
      "Thalassemia    100\n",
      "Thrombosis     100\n",
      "Diabetes       100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Disease English antes de undersampling:\")\n",
    "print(df_disease_sp['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que ya las clases est谩n bien distribuidas. Dividimos el dataset en conjunto de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento:\n",
      "Disease\n",
      "Thrombosis     64\n",
      "Anemia         64\n",
      "Thalassemia    64\n",
      "Diabetes       64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de validaci贸n:\n",
      "Disease\n",
      "Thrombosis     16\n",
      "Thalassemia    16\n",
      "Anemia         16\n",
      "Diabetes       16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de prueba:\n",
      "Disease\n",
      "Thalassemia    20\n",
      "Diabetes       20\n",
      "Anemia         20\n",
      "Thrombosis     20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dividiamo il dataset bilanciato in train (80%) e test (20%)\n",
    "train_df, test_df = train_test_split(df_disease_sp, test_size=0.2, random_state=42, stratify=df_disease_sp['Disease'])\n",
    "\n",
    "# Dividiamo ulteriormente il train in train (80%) e validation (20%)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Disease'])\n",
    "\n",
    "# Verifichiamo che i set siano equilibrati\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de validaci贸n:\")\n",
    "print(val_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Ive noticed my leg is swollen, and the veins ...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ive been getting infections a lot, and my ski...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Ive been so weak lately, and my skin looks ye...</td>\n",
       "      <td>Thalassemia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Ive noticed that the whites of my eyes have a...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>My visions been blurry, Im constantly thirst...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Symptoms      Disease  label\n",
       "281  Ive noticed my leg is swollen, and the veins ...   Thrombosis      3\n",
       "22   Ive been getting infections a lot, and my ski...       Anemia      0\n",
       "146  Ive been so weak lately, and my skin looks ye...  Thalassemia      2\n",
       "70   Ive noticed that the whites of my eyes have a...       Anemia      0\n",
       "376  My visions been blurry, Im constantly thirst...     Diabetes      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un codificador de etiquetas para convertir las clases de texto en n煤meros\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir las clases de 'Disease' a n煤meros\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['Disease'])\n",
    "val_df['label'] = label_encoder.transform(val_df['Disease'])\n",
    "test_df['label'] = label_encoder.transform(test_df['Disease'])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la funci贸n de m茅tricas\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
    "        \"precision\": precision_score(p.label_ids, preds, average='macro'),\n",
    "        \"recall\": recall_score(p.label_ids, preds, average='macro'),\n",
    "        \"f1\": f1_score(p.label_ids, preds, average='macro'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeb97ec33c94d99a9062dfd378b6949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maria\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850c15ca0844cbd876dc8c1334cab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b488612a98ad4f8c8d45c3d3ba99edcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728c372ba4034053af5e0c3ef276a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6495b1b2164994bbc19dd4adf29a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo y el tokenizer\n",
    "model_checkpoint = \"distilbert-base-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos los datos\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['Symptoms'], examples['Disease'], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b87a796a8a403387b8addca7142251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a945df3c4f2a4e43bf7b7f787aa6a56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aee0af90b9492690306ea03fd0df22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converti i DataFrame in dataset di Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "validation_dataset = Dataset.from_pandas(val_df)\n",
    "# Tokenizamos el dataset\n",
    "train_preprocessed_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "val_preprocessed_dataset = validation_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_25044\\2732148159.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,              # Tasa de aprendizaje: se ha probado 5e-6, 1e-5, 5e-5\n",
    "    per_device_train_batch_size=32,   # Tama帽o del batch para entrenamiento: se ha probado 8, 16, 32, 64\n",
    "    per_device_eval_batch_size=32,    # Tama帽o del batch para evaluaci贸n\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,               # Decaimiento de peso: hemos probado 0.01, 0.1, 0.2 e 0.3 e 0.4 y este era el mejor\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_preprocessed_dataset,\n",
    "    eval_dataset=val_preprocessed_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics   # Funci贸n para calcular las m茅tricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Symptoms', 'Disease', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 256\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3483c881bce422ba02227d275700bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53da099f0f24550b994b7e23ae45ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3688021898269653, 'eval_accuracy': 0.296875, 'eval_precision': 0.40350877192982454, 'eval_recall': 0.296875, 'eval_f1': 0.1844553512563182, 'eval_runtime': 1.0749, 'eval_samples_per_second': 59.54, 'eval_steps_per_second': 1.861, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e31c7b5c8b428eada7a287f4303cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3432338237762451, 'eval_accuracy': 0.53125, 'eval_precision': 0.7159090909090909, 'eval_recall': 0.53125, 'eval_f1': 0.48641863278886877, 'eval_runtime': 1.2903, 'eval_samples_per_second': 49.601, 'eval_steps_per_second': 1.55, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1fecca447b4a60ae44985efa76e60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3304280042648315, 'eval_accuracy': 0.578125, 'eval_precision': 0.8285714285714285, 'eval_recall': 0.578125, 'eval_f1': 0.5383406606988365, 'eval_runtime': 1.477, 'eval_samples_per_second': 43.331, 'eval_steps_per_second': 1.354, 'epoch': 3.0}\n",
      "{'train_runtime': 66.5161, 'train_samples_per_second': 11.546, 'train_steps_per_second': 0.361, 'train_loss': 1.3562766710917156, 'epoch': 3.0}\n",
      ">>>>>>>>>>>>> elapsed time: 1m\n"
     ]
    }
   ],
   "source": [
    "# No modificar esta celda\n",
    "# Esta celda, celda tiene que estar ejecutada en la entrega\n",
    "\n",
    "start = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end = time()\n",
    "print(f\">>>>>>>>>>>>> elapsed time: {(end-start)/60:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c380951cd445e4ba299adbe85c2ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdba6d660254895af121f043d01d735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la evaluaci贸n en el conjunto de prueba:\n",
      "Exactitud: 0.7000\n",
      "Precisi贸n: 0.8636\n",
      "Recall: 0.7000\n",
      "F1-Score: 0.6801\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci贸n del modelo en el conjunto de prueba\n",
    "\n",
    "# Preprocesamos el conjunto de prueba\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluamos el modelo en el conjunto de prueba\n",
    "results = trainer.evaluate(test_preprocessed_dataset)\n",
    "\n",
    "# Imprimimos las m茅tricas de evaluaci贸n\n",
    "print(\"Resultados de la evaluaci贸n en el conjunto de prueba:\")\n",
    "print(f\"Exactitud: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precisi贸n: {results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo y el tokenizer\n",
    "save_directory = os.path.join(MODELS_LOCATION, 'disease_classification_spanish_nlp')\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(f\"Modelo y tokenizer guardados en el directorio {save_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos algunas frases de ejemplo para el test que puedan confundir a nuestro modelo\n",
    "sample_sentences = [\n",
    "    {\"S铆ntomas\": \"Me siento cansado todo el tiempo, como si no tuviera energ铆a para nada.\", \"Enfermedad\": \"Anemia\"},\n",
    "    {\"S铆ntomas\": \"Mi hijo no crece como deber铆a y siempre se queja de estar d茅bil.\", \"Enfermedad\": \"Talasemia\"},\n",
    "    {\"S铆ntomas\": \"Tengo dolores en los huesos y me siento agotado incluso despu茅s de descansar.\", \"Enfermedad\": \"Talasemia\"},\n",
    "    {\"S铆ntomas\": \"Tengo mucha sed todo el tiempo y no dejo de ir al ba帽o.\", \"Enfermedad\": \"Diabetes\"},\n",
    "    {\"S铆ntomas\": \"Tengo un dolor punzante y la pierna est谩 hinchada y roja.\", \"Enfermedad\": \"Trombosis\"},\n",
    "    {\"S铆ntomas\": \"He bajado de peso sin raz贸n y me siento muy cansado.\", \"Enfermedad\": \"Diabetes\"}\n",
    "]\n",
    "\n",
    "# Convertiamo le frasi di esempio in un DataFrame\n",
    "sample_df = pd.DataFrame(sample_sentences)\n",
    "\n",
    "# Tokenizziamo le frasi di esempio\n",
    "sample_dataset = Dataset.from_pandas(sample_df)\n",
    "sample_preprocessed_dataset = sample_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Effettuiamo le predizioni\n",
    "sample_predictions = trainer.predict(sample_preprocessed_dataset)\n",
    "sample_preds = np.argmax(sample_predictions.predictions, axis=1)\n",
    "sample_df[\"Enfermedad predicha\"] = label_encoder.inverse_transform(sample_preds)\n",
    "\n",
    "# Mostriamo i risultati\n",
    "print(\"Resultados de las predicciones en las frases de ejemplo:\")\n",
    "sample_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
