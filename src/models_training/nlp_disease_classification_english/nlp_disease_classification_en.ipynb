{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la carpeta actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "DATASETS_LOCATION = os.path.join(current_dir.parent.parent.parent, 'datasets')\n",
    "MODELS_LOCATION = os.path.join(current_dir.parent.parent, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been feeling tired all the time and notic...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lately, I’ve been out of breath even after lig...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the past few weeks, I’ve been extremely we...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms Disease\n",
       "0  I've been feeling tired all the time and notic...  Anemia\n",
       "1  Lately, I’ve been out of breath even after lig...  Anemia\n",
       "2  For the past few weeks, I’ve been extremely we...  Anemia"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disease_sp = pd.read_excel(os.path.join(DATASETS_LOCATION, 'disease_nlp_eng.xlsx'))\n",
    "df_disease_sp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease\n",
      "Anemia         100\n",
      "Thalassemia    100\n",
      "Thrombosis     100\n",
      "Diabetes       100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_disease_sp['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que ya las clases están bien distribuidas. Dividimos el dataset en conjunto de entrenamiento y prueba, y a su vez el conjunto de entrenamiento lo dividiremos en conjunto de entrenamiento y conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento:\n",
      "Disease\n",
      "Thrombosis     64\n",
      "Anemia         64\n",
      "Thalassemia    64\n",
      "Diabetes       64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de validación:\n",
      "Disease\n",
      "Thrombosis     16\n",
      "Thalassemia    16\n",
      "Anemia         16\n",
      "Diabetes       16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de prueba:\n",
      "Disease\n",
      "Thalassemia    20\n",
      "Diabetes       20\n",
      "Anemia         20\n",
      "Thrombosis     20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_disease_sp, test_size=0.2, random_state=42, stratify=df_disease_sp['Disease'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Disease'])\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "print(val_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos las clases de 'Disease', utilizando LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>I’ve noticed my leg is swollen, and the veins ...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I’ve been getting infections a lot, and my ski...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>I’ve been so weak lately, and my skin looks ye...</td>\n",
       "      <td>Thalassemia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>I’ve noticed that the whites of my eyes have a...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>My vision’s been blurry, I’m constantly thirst...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Symptoms      Disease  label\n",
       "281  I’ve noticed my leg is swollen, and the veins ...   Thrombosis      3\n",
       "22   I’ve been getting infections a lot, and my ski...       Anemia      0\n",
       "146  I’ve been so weak lately, and my skin looks ye...  Thalassemia      2\n",
       "70   I’ve noticed that the whites of my eyes have a...       Anemia      0\n",
       "376  My vision’s been blurry, I’m constantly thirst...     Diabetes      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['Disease'])\n",
    "val_df['label'] = label_encoder.transform(val_df['Disease'])\n",
    "test_df['label'] = label_encoder.transform(test_df['Disease'])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la función de métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
    "        \"precision\": precision_score(p.label_ids, preds, average='macro'),\n",
    "        \"recall\": recall_score(p.label_ids, preds, average='macro'),\n",
    "        \"f1\": f1_score(p.label_ids, preds, average='macro'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo y el tokenizador. En este caso, utilizaremos el modelo preentrenado de hugging face 'Distilbert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos los datos\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['Symptoms'], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los dataframe en datasets de hugging face, y los tokenizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883f2a6dceba45d493a2b8c13f3f3eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f48661890c404c9d4a945da72d662f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21519fd9cbe484aa8f59564515c940d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "validation_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_preprocessed_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "val_preprocessed_dataset = validation_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_8052\\3686964481.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,              # Tasa de aprendizaje: se ha probado 5e-6, 1e-5, 5e-5, 2e-5\n",
    "    per_device_train_batch_size=16,   # Tamaño del batch para entrenamiento: se ha probado 8, 16, 32, 64\n",
    "    per_device_eval_batch_size=16,    # Tamaño del batch para evaluación\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.2,               # Decaimiento de peso: hemos probado 0.01, 0.03, 0.1, 0.2, 0.3 y 0.4\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_preprocessed_dataset,\n",
    "    eval_dataset=val_preprocessed_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics   # Función para calcular las métricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8e3afcc1ce452a8f7524f18d4a1678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770e85ae2f9e4f4ab68938cad6770e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2458349466323853, 'eval_accuracy': 0.75, 'eval_precision': 0.8128582202111614, 'eval_recall': 0.75, 'eval_f1': 0.734778662198017, 'eval_runtime': 0.9042, 'eval_samples_per_second': 70.783, 'eval_steps_per_second': 4.424, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cede502b51db40da91f4bdc2d05e7bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9477478265762329, 'eval_accuracy': 0.765625, 'eval_precision': 0.7991071428571428, 'eval_recall': 0.765625, 'eval_f1': 0.7502705627705628, 'eval_runtime': 0.9466, 'eval_samples_per_second': 67.607, 'eval_steps_per_second': 4.225, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9c02cba5c4419fb06a729d29bfb875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.682657778263092, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.9709, 'eval_samples_per_second': 65.92, 'eval_steps_per_second': 4.12, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d9158befb4a7a926ae3cf04b995df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5084469318389893, 'eval_accuracy': 0.921875, 'eval_precision': 0.9404761904761905, 'eval_recall': 0.921875, 'eval_f1': 0.91991991991992, 'eval_runtime': 0.8657, 'eval_samples_per_second': 73.927, 'eval_steps_per_second': 4.62, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39044968e2748c09909a4f5681471f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40697821974754333, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.8461, 'eval_samples_per_second': 75.64, 'eval_steps_per_second': 4.727, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ee2d27ed8d4b64be95083cb74e457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3495428264141083, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.9089, 'eval_samples_per_second': 70.417, 'eval_steps_per_second': 4.401, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c99a1ae30d4dea8f19cf9212e48f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3341251015663147, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 1.0671, 'eval_samples_per_second': 59.977, 'eval_steps_per_second': 3.749, 'epoch': 7.0}\n",
      "{'train_runtime': 122.919, 'train_samples_per_second': 14.579, 'train_steps_per_second': 0.911, 'train_loss': 0.7061257362365723, 'epoch': 7.0}\n",
      ">>>>>>>>>>>>> elapsed time: 2m\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end = time()\n",
    "print(f\">>>>>>>>>>>>> elapsed time: {(end-start)/60:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02921be77fd641c3b5b9996d9178dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la evaluación en el conjunto de prueba:\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9773\n",
      "Recall: 0.9750\n",
      "F1-Score: 0.9749\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_preprocessed_dataset)\n",
    "\n",
    "# Imprimimos las métricas de evaluación\n",
    "print(\"Resultados de la evaluación en el conjunto de prueba:\")\n",
    "print(f\"Accuracy: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como observamos, se obtiene una accuracy en train de 0.9531, y en test de 0.975. Por lo tanto, nuestro modelo no presenta overfitting. Tal y como vemos, no se alcanza una accuracy de 1. Esto se debe a que las diferentes enfermedades que el modelo clasifica, tienen síntomas comunes entre ellas, o entre algunas de ellas, haciendo difícil para el modelo poder distinguirlas basándose símplemente en los síntomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo y el tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en el directorio c:\\Users\\maria\\Desktop\\universidad\\master\\TFM\\tfm\\src\\models\\disease_classification_english_nlp\n"
     ]
    }
   ],
   "source": [
    "'''save_directory = os.path.join(MODELS_LOCATION, 'disease_classification_english_nlp')\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(f\"Modelo y tokenizer guardados en el directorio {save_directory}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos algunas frases de ejemplo para el test, que puedan confundir a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1880c8db1f604d2dbb537c6eb851a68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc3622f5cb744cd8b7854797935ab83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de las predicciones en las frases de ejemplo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Predicted disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My vision has been blurry lately, and I feel s...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’ve been feeling unusually weak and cold all ...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There’s a strange heaviness in my leg, and it’...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>Thrombosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My skin looks yellowish, and I often feel shor...</td>\n",
       "      <td>Thalassemia</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I get out of breath even when doing small task...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I’ve noticed a lot of pain in my calf, and it ...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>Thrombosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms      Disease  \\\n",
       "0  My vision has been blurry lately, and I feel s...     Diabetes   \n",
       "1  I’ve been feeling unusually weak and cold all ...       Anemia   \n",
       "2  There’s a strange heaviness in my leg, and it’...   Thrombosis   \n",
       "3  My skin looks yellowish, and I often feel shor...  Thalassemia   \n",
       "4  I get out of breath even when doing small task...       Anemia   \n",
       "5  I’ve noticed a lot of pain in my calf, and it ...   Thrombosis   \n",
       "\n",
       "  Predicted disease  \n",
       "0          Diabetes  \n",
       "1            Anemia  \n",
       "2        Thrombosis  \n",
       "3          Diabetes  \n",
       "4            Anemia  \n",
       "5        Thrombosis  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences = [\n",
    "    {\"Symptoms\": \"My vision has been blurry lately, and I feel so drained.\", \"Disease\": \"Diabetes\"},\n",
    "    {\"Symptoms\": \"I’ve been feeling unusually weak and cold all the time.\", \"Disease\": \"Anemia\"},\n",
    "    {\"Symptoms\": \"There’s a strange heaviness in my leg, and it’s very swollen.\", \"Disease\": \"Thrombosis\"},\n",
    "    {\"Symptoms\": \"My skin looks yellowish, and I often feel short of breath.\", \"Disease\": \"Thalassemia\"},\n",
    "    {\"Symptoms\": \"I get out of breath even when doing small tasks, and my heart feels like it’s racing.\", \"Disease\": \"Anemia\"},\n",
    "    {\"Symptoms\": \"I’ve noticed a lot of pain in my calf, and it seems warmer than usual.\", \"Disease\": \"Thrombosis\"}\n",
    "]\n",
    "\n",
    "# Convertamos las frases de ejemplo en un dataframe\n",
    "sample_df = pd.DataFrame(sample_sentences)\n",
    "\n",
    "# Tokenizamos las frases de ejemplo\n",
    "sample_dataset = Dataset.from_pandas(sample_df)\n",
    "sample_preprocessed_dataset = sample_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Efectuemos las predicciones\n",
    "sample_predictions = trainer.predict(sample_preprocessed_dataset)\n",
    "sample_preds = np.argmax(sample_predictions.predictions, axis=1)\n",
    "sample_df[\"Predicted disease\"] = label_encoder.inverse_transform(sample_preds)\n",
    "\n",
    "print(\"Resultados de las predicciones en las frases de ejemplo:\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test para comprobar que el modelo carga correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy del modelo es: 0.97\n"
     ]
    }
   ],
   "source": [
    "model_directory = os.path.join(MODELS_LOCATION, 'disease_classification_english_nlp')\n",
    "# Cargamos el tokenizer y el modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory, local_files_only=True)\n",
    "model_loaded = AutoModelForSequenceClassification.from_pretrained(model_directory, local_files_only=True)\n",
    "def classify_disease_symptoms(input_text: str) -> str:\n",
    "    prediction_mapping = {0: 'Anemia',\n",
    "                          1: 'Diabetes', \n",
    "                          2: 'Thalassemia', \n",
    "                          3: 'Thrombosis'}\n",
    "    # Tokenizamos las frases\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # Efectuamos las predicciones\n",
    "    with torch.no_grad():\n",
    "        outputs = model_loaded(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, axis=1).item()\n",
    "    return prediction_mapping[prediction]\n",
    "\n",
    "# Añadimos una columna con las predicciones\n",
    "def add_predictions(df):\n",
    "    df['Predicted Disease'] = df['Symptoms'].apply(classify_disease_symptoms)\n",
    "    return df\n",
    "\n",
    "# Actualizamos el dataframe con las predicciones\n",
    "predicciones = add_predictions(test_df)\n",
    "# Extraemos los valores reales y predichos\n",
    "true_values = predicciones['Disease']\n",
    "predicted_values = predicciones['Predicted Disease']\n",
    "\n",
    "# Calculamos la accuracy\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(f\"La accuracy del modelo es: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el modelo se ha cargado correctamente y que su rendimiento no se ha alterado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
