{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la carpeta actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "DATASETS_LOCATION = os.path.join(current_dir.parent.parent.parent, 'datasets')\n",
    "MODELS_LOCATION = os.path.join(current_dir.parent.parent, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset en un dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've been feeling tired all the time and notic...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lately, Iâ€™ve been out of breath even after lig...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the past few weeks, Iâ€™ve been extremely we...</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms Disease\n",
       "0  I've been feeling tired all the time and notic...  Anemia\n",
       "1  Lately, Iâ€™ve been out of breath even after lig...  Anemia\n",
       "2  For the past few weeks, Iâ€™ve been extremely we...  Anemia"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disease_sp = pd.read_excel(os.path.join(DATASETS_LOCATION, 'disease_nlp_eng.xlsx'))\n",
    "df_disease_sp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease\n",
      "Anemia         100\n",
      "Thalassemia    100\n",
      "Thrombosis     100\n",
      "Diabetes       100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_disease_sp['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que ya las clases estÃ¡n bien distribuidas. Dividimos el dataset en conjunto de entrenamiento y prueba, y a su vez el conjunto de entrenamiento lo dividiremos en conjunto de entrenamiento y conjunto de validaciÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento:\n",
      "Disease\n",
      "Thrombosis     64\n",
      "Anemia         64\n",
      "Thalassemia    64\n",
      "Diabetes       64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de validaciÃ³n:\n",
      "Disease\n",
      "Thrombosis     16\n",
      "Thalassemia    16\n",
      "Anemia         16\n",
      "Diabetes       16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de prueba:\n",
      "Disease\n",
      "Thalassemia    20\n",
      "Diabetes       20\n",
      "Anemia         20\n",
      "Thrombosis     20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_disease_sp, test_size=0.2, random_state=42, stratify=df_disease_sp['Disease'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Disease'])\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de validaciÃ³n:\")\n",
    "print(val_df['Disease'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos las clases de 'Disease', utilizando LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Iâ€™ve noticed my leg is swollen, and the veins ...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Iâ€™ve been getting infections a lot, and my ski...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Iâ€™ve been so weak lately, and my skin looks ye...</td>\n",
       "      <td>Thalassemia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Iâ€™ve noticed that the whites of my eyes have a...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>My visionâ€™s been blurry, Iâ€™m constantly thirst...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Symptoms      Disease  label\n",
       "281  Iâ€™ve noticed my leg is swollen, and the veins ...   Thrombosis      3\n",
       "22   Iâ€™ve been getting infections a lot, and my ski...       Anemia      0\n",
       "146  Iâ€™ve been so weak lately, and my skin looks ye...  Thalassemia      2\n",
       "70   Iâ€™ve noticed that the whites of my eyes have a...       Anemia      0\n",
       "376  My visionâ€™s been blurry, Iâ€™m constantly thirst...     Diabetes      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['Disease'])\n",
    "val_df['label'] = label_encoder.transform(val_df['Disease'])\n",
    "test_df['label'] = label_encoder.transform(test_df['Disease'])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos la funciÃ³n de mÃ©tricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
    "        \"precision\": precision_score(p.label_ids, preds, average='macro'),\n",
    "        \"recall\": recall_score(p.label_ids, preds, average='macro'),\n",
    "        \"f1\": f1_score(p.label_ids, preds, average='macro'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo y el tokenizador. En este caso, utilizaremos el modelo preentrenado de hugging face 'Distilbert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos los datos\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['Symptoms'], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos los dataframe en datasets de hugging face, y los tokenizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883f2a6dceba45d493a2b8c13f3f3eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f48661890c404c9d4a945da72d662f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21519fd9cbe484aa8f59564515c940d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "validation_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_preprocessed_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "val_preprocessed_dataset = validation_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_8052\\3686964481.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,              # Tasa de aprendizaje: se ha probado 5e-6, 1e-5, 5e-5, 2e-5\n",
    "    per_device_train_batch_size=16,   # TamaÃ±o del batch para entrenamiento: se ha probado 8, 16, 32, 64\n",
    "    per_device_eval_batch_size=16,    # TamaÃ±o del batch para evaluaciÃ³n\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.2,               # Decaimiento de peso: hemos probado 0.01, 0.03, 0.1, 0.2, 0.3 y 0.4\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_preprocessed_dataset,\n",
    "    eval_dataset=val_preprocessed_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics   # FunciÃ³n para calcular las mÃ©tricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8e3afcc1ce452a8f7524f18d4a1678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770e85ae2f9e4f4ab68938cad6770e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2458349466323853, 'eval_accuracy': 0.75, 'eval_precision': 0.8128582202111614, 'eval_recall': 0.75, 'eval_f1': 0.734778662198017, 'eval_runtime': 0.9042, 'eval_samples_per_second': 70.783, 'eval_steps_per_second': 4.424, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cede502b51db40da91f4bdc2d05e7bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9477478265762329, 'eval_accuracy': 0.765625, 'eval_precision': 0.7991071428571428, 'eval_recall': 0.765625, 'eval_f1': 0.7502705627705628, 'eval_runtime': 0.9466, 'eval_samples_per_second': 67.607, 'eval_steps_per_second': 4.225, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9c02cba5c4419fb06a729d29bfb875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.682657778263092, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.9709, 'eval_samples_per_second': 65.92, 'eval_steps_per_second': 4.12, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d9158befb4a7a926ae3cf04b995df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5084469318389893, 'eval_accuracy': 0.921875, 'eval_precision': 0.9404761904761905, 'eval_recall': 0.921875, 'eval_f1': 0.91991991991992, 'eval_runtime': 0.8657, 'eval_samples_per_second': 73.927, 'eval_steps_per_second': 4.62, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39044968e2748c09909a4f5681471f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40697821974754333, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.8461, 'eval_samples_per_second': 75.64, 'eval_steps_per_second': 4.727, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ee2d27ed8d4b64be95083cb74e457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3495428264141083, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 0.9089, 'eval_samples_per_second': 70.417, 'eval_steps_per_second': 4.401, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c99a1ae30d4dea8f19cf9212e48f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3341251015663147, 'eval_accuracy': 0.953125, 'eval_precision': 0.9605263157894737, 'eval_recall': 0.953125, 'eval_f1': 0.9527093596059113, 'eval_runtime': 1.0671, 'eval_samples_per_second': 59.977, 'eval_steps_per_second': 3.749, 'epoch': 7.0}\n",
      "{'train_runtime': 122.919, 'train_samples_per_second': 14.579, 'train_steps_per_second': 0.911, 'train_loss': 0.7061257362365723, 'epoch': 7.0}\n",
      ">>>>>>>>>>>>> elapsed time: 2m\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end = time()\n",
    "print(f\">>>>>>>>>>>>> elapsed time: {(end-start)/60:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EvaluaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02921be77fd641c3b5b9996d9178dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la evaluaciÃ³n en el conjunto de prueba:\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9773\n",
      "Recall: 0.9750\n",
      "F1-Score: 0.9749\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_preprocessed_dataset)\n",
    "\n",
    "# Imprimimos las mÃ©tricas de evaluaciÃ³n\n",
    "print(\"Resultados de la evaluaciÃ³n en el conjunto de prueba:\")\n",
    "print(f\"Accuracy: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal y como observamos, se obtiene una accuracy en train de 0.9531, y en test de 0.975. Por lo tanto, nuestro modelo no presenta overfitting. Tal y como vemos, no se alcanza una accuracy de 1. Esto se debe a que las diferentes enfermedades que el modelo clasifica, tienen sÃ­ntomas comunes entre ellas, o entre algunas de ellas, haciendo difÃ­cil para el modelo poder distinguirlas basÃ¡ndose sÃ­mplemente en los sÃ­ntomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo y el tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en el directorio c:\\Users\\maria\\Desktop\\universidad\\master\\TFM\\tfm\\src\\models\\disease_classification_english_nlp\n"
     ]
    }
   ],
   "source": [
    "'''save_directory = os.path.join(MODELS_LOCATION, 'disease_classification_english_nlp')\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(f\"Modelo y tokenizer guardados en el directorio {save_directory}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos algunas frases de ejemplo para el test, que puedan confundir a nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1880c8db1f604d2dbb537c6eb851a68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc3622f5cb744cd8b7854797935ab83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de las predicciones en las frases de ejemplo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symptoms</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Predicted disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My vision has been blurry lately, and I feel s...</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iâ€™ve been feeling unusually weak and cold all ...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thereâ€™s a strange heaviness in my leg, and itâ€™...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>Thrombosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My skin looks yellowish, and I often feel shor...</td>\n",
       "      <td>Thalassemia</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I get out of breath even when doing small task...</td>\n",
       "      <td>Anemia</td>\n",
       "      <td>Anemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iâ€™ve noticed a lot of pain in my calf, and it ...</td>\n",
       "      <td>Thrombosis</td>\n",
       "      <td>Thrombosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Symptoms      Disease  \\\n",
       "0  My vision has been blurry lately, and I feel s...     Diabetes   \n",
       "1  Iâ€™ve been feeling unusually weak and cold all ...       Anemia   \n",
       "2  Thereâ€™s a strange heaviness in my leg, and itâ€™...   Thrombosis   \n",
       "3  My skin looks yellowish, and I often feel shor...  Thalassemia   \n",
       "4  I get out of breath even when doing small task...       Anemia   \n",
       "5  Iâ€™ve noticed a lot of pain in my calf, and it ...   Thrombosis   \n",
       "\n",
       "  Predicted disease  \n",
       "0          Diabetes  \n",
       "1            Anemia  \n",
       "2        Thrombosis  \n",
       "3          Diabetes  \n",
       "4            Anemia  \n",
       "5        Thrombosis  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences = [\n",
    "    {\"Symptoms\": \"My vision has been blurry lately, and I feel so drained.\", \"Disease\": \"Diabetes\"},\n",
    "    {\"Symptoms\": \"Iâ€™ve been feeling unusually weak and cold all the time.\", \"Disease\": \"Anemia\"},\n",
    "    {\"Symptoms\": \"Thereâ€™s a strange heaviness in my leg, and itâ€™s very swollen.\", \"Disease\": \"Thrombosis\"},\n",
    "    {\"Symptoms\": \"My skin looks yellowish, and I often feel short of breath.\", \"Disease\": \"Thalassemia\"},\n",
    "    {\"Symptoms\": \"I get out of breath even when doing small tasks, and my heart feels like itâ€™s racing.\", \"Disease\": \"Anemia\"},\n",
    "    {\"Symptoms\": \"Iâ€™ve noticed a lot of pain in my calf, and it seems warmer than usual.\", \"Disease\": \"Thrombosis\"}\n",
    "]\n",
    "\n",
    "# Convertamos las frases de ejemplo en un dataframe\n",
    "sample_df = pd.DataFrame(sample_sentences)\n",
    "\n",
    "# Tokenizamos las frases de ejemplo\n",
    "sample_dataset = Dataset.from_pandas(sample_df)\n",
    "sample_preprocessed_dataset = sample_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Efectuemos las predicciones\n",
    "sample_predictions = trainer.predict(sample_preprocessed_dataset)\n",
    "sample_preds = np.argmax(sample_predictions.predictions, axis=1)\n",
    "sample_df[\"Predicted disease\"] = label_encoder.inverse_transform(sample_preds)\n",
    "\n",
    "print(\"Resultados de las predicciones en las frases de ejemplo:\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test para comprobar que el modelo carga correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La accuracy del modelo es: 0.97\n"
     ]
    }
   ],
   "source": [
    "model_directory = os.path.join(MODELS_LOCATION, 'disease_classification_english_nlp')\n",
    "# Cargamos el tokenizer y el modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory, local_files_only=True)\n",
    "model_loaded = AutoModelForSequenceClassification.from_pretrained(model_directory, local_files_only=True)\n",
    "def classify_disease_symptoms(input_text: str) -> str:\n",
    "    prediction_mapping = {0: 'Anemia',\n",
    "                          1: 'Diabetes', \n",
    "                          2: 'Thalassemia', \n",
    "                          3: 'Thrombosis'}\n",
    "    # Tokenizamos las frases\n",
    "    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # Efectuamos las predicciones\n",
    "    with torch.no_grad():\n",
    "        outputs = model_loaded(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, axis=1).item()\n",
    "    return prediction_mapping[prediction]\n",
    "\n",
    "# AÃ±adimos una columna con las predicciones\n",
    "def add_predictions(df):\n",
    "    df['Predicted Disease'] = df['Symptoms'].apply(classify_disease_symptoms)\n",
    "    return df\n",
    "\n",
    "# Actualizamos el dataframe con las predicciones\n",
    "predicciones = add_predictions(test_df)\n",
    "# Extraemos los valores reales y predichos\n",
    "true_values = predicciones['Disease']\n",
    "predicted_values = predicciones['Predicted Disease']\n",
    "\n",
    "# Calculamos la accuracy\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "\n",
    "# Mostramos el resultado\n",
    "print(f\"La accuracy del modelo es: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el modelo se ha cargado correctamente y que su rendimiento no se ha alterado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
