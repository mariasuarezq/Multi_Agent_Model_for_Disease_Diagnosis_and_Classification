{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la carpeta actual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path.cwd()\n",
    "DATASETS_LOCATION = os.path.join(current_dir.parent.parent.parent, 'datasets')\n",
    "MODELS_LOCATION = os.path.join(current_dir.parent.parent, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset, y filtramos por los idiomas español e inglés, que son los que nos interesan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_languages = pd.read_csv(os.path.join(DATASETS_LOCATION, 'language_detection.csv'))\n",
    "\n",
    "# Filtramos por idioma español e inglés\n",
    "df_spanish_english = df_all_languages[df_all_languages['Language'].isin(['Spanish', 'English'])]\n",
    "df_spanish_english.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos que de ambas clases haya el mismo número de ejemplos, primero determinamos la cantidad de ejemplos que hay de cada clase, para posteriormente equilibrarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Language distribution antes de undersampling:\n",
      "Language\n",
      "English    1385\n",
      "Spanish     819\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Dataset Language distribution despues de undersampling:\n",
      "Language\n",
      "English    819\n",
      "Spanish    819\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Language distribution antes de undersampling:\")\n",
    "print(df_spanish_english['Language'].value_counts())\n",
    "\n",
    "# Determinamos la cantidad mínima de ejemplos por clase\n",
    "min_count = min(df_spanish_english['Language'].value_counts())\n",
    "\n",
    "# Submuestreamos para equilibrar las clases\n",
    "df_balanced = pd.concat([\n",
    "    df_spanish_english[df_spanish_english['Language'] == 'English'].sample(n=min_count, random_state=42),\n",
    "    df_spanish_english[df_spanish_english['Language'] == 'Spanish']\n",
    "])\n",
    "\n",
    "# Verificamos el equilibrio\n",
    "print(\"\\n Dataset Language distribution después de undersampling:\")\n",
    "print(df_balanced['Language'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el dataset balanceado (que será el dataset que utilizaremos de ahora en adelante), en conjunto de entrenamiento y prueba, y el dataset de entrenamiento en entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento:\n",
      "Language\n",
      "Spanish    524\n",
      "English    524\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de validación:\n",
      "Language\n",
      "Spanish    131\n",
      "English    131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Conjunto de prueba:\n",
      "Language\n",
      "English    164\n",
      "Spanish    164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df_balanced, test_size=0.2, random_state=42, stratify=df_balanced['Language'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Language'])\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df['Language'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "print(val_df['Language'].value_counts())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df['Language'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificamos mediante LabelEncoder las clases de 'Language':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>El proyecto tuvo el apoyo económico de la empr...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>In Linnaeus' system, these became the kingdoms...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>It is a powerful tool we are only just beginni...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>Por lo tanto es un proceso de inducción del co...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Notably, the results of a Wikimedia Foundation...</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language  label\n",
       "4853  El proyecto tuvo el apoyo económico de la empr...  Spanish      1\n",
       "177   In Linnaeus' system, these became the kingdoms...  English      0\n",
       "1008  It is a powerful tool we are only just beginni...  English      0\n",
       "5163  Por lo tanto es un proceso de inducción del co...  Spanish      1\n",
       "413   Notably, the results of a Wikimedia Foundation...  English      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['Language'])\n",
    "val_df['label'] = label_encoder.transform(val_df['Language'])\n",
    "test_df['label'] = label_encoder.transform(test_df['Language'])\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función de métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds),\n",
    "        \"precision\": precision_score(p.label_ids, preds, average='macro'),\n",
    "        \"recall\": recall_score(p.label_ids, preds, average='macro'),\n",
    "        \"f1\": f1_score(p.label_ids, preds, average='macro'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y definimos el modelo que vamos a utilizar y el tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-multilingual-cased\"  # Usaremos el modelo preentrenado distilbert\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['Text'], examples['Language'], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y convertimos el dataframe en un dataset de Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b6ec8a5eaa42a6b55f1adf5c993771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1048 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec6c6cdee4b4b70a7fa644f8cd59dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/328 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85b15d2b6ca4aac8031796ec379acd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "validation_dataset = Dataset.from_pandas(val_df)\n",
    "# Tokenizamos el dataset\n",
    "train_preprocessed_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "val_preprocessed_dataset = validation_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_16120\\2732148159.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,              # Tasa de aprendizaje: se ha probado 5e-6, 1e-5, 5e-5\n",
    "    per_device_train_batch_size=32,   # Tamaño del batch para entrenamiento: se ha probado 8, 16, 32, 64\n",
    "    per_device_eval_batch_size=32,    # Tamaño del batch para evaluación\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.3,               # Decaimiento de peso: hemos probado 0.01, 0.1, 0.2 e 0.3 e 0.4 y este era el mejor\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_preprocessed_dataset,\n",
    "    eval_dataset=val_preprocessed_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics   # Función para calcular las métricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamos el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Language', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1048\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac421feab6a14f96830aff0244e46913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2320dc2d9de4814a5e676ba0cf9a63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2956748604774475, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 15.3924, 'eval_samples_per_second': 17.021, 'eval_steps_per_second': 0.585, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4459a62a12c3449da55ad5200b239ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03905799984931946, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 15.8469, 'eval_samples_per_second': 16.533, 'eval_steps_per_second': 0.568, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1c93f6d61f41f2b261d1f17b6baa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023262353613972664, 'eval_accuracy': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 13.9239, 'eval_samples_per_second': 18.817, 'eval_steps_per_second': 0.646, 'epoch': 3.0}\n",
      "{'train_runtime': 862.1471, 'train_samples_per_second': 3.647, 'train_steps_per_second': 0.115, 'train_loss': 0.24847824404938051, 'epoch': 3.0}\n",
      ">>>>>>>>>>>>> elapsed time: 14m\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end = time()\n",
    "print(f\">>>>>>>>>>>>> elapsed time: {(end-start)/60:.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9a25f0e68846be99c0d04c321ffa01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/328 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892b75bc67d045d3bd170b4e1eaf4ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la evaluación en el conjunto de prueba:\n",
      "Exactitud: 1.0000\n",
      "Precisión: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamos el conjunto de prueba\n",
    "test_preprocessed_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Evaluamos el modelo en el conjunto de prueba\n",
    "results = trainer.evaluate(test_preprocessed_dataset)\n",
    "\n",
    "# Imprimimos las métricas de evaluación\n",
    "print(\"Resultados de la evaluación en el conjunto de prueba:\")\n",
    "print(f\"Exactitud: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precisión: {results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score: {results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo y el tokenizer en un directorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en el directorio c:\\Users\\maria\\Desktop\\universidad\\master\\TFM\\tfm\\src\\models\\language_detection\n"
     ]
    }
   ],
   "source": [
    "save_directory = os.path.join(MODELS_LOCATION, 'language_detection')\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "print(f\"Modelo y tokenizer guardados en el directorio {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definamos algunas frases de ejemplo para hacer una prueba, que puedan confundir el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd80ee5bfe6b4014861278e4f071abec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f492a11b57364707a35d3b4d1a6dae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de las predicciones en las frases de ejemplo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Predicted Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you want tortilla for dinner?</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este es un ejemplo de software developement.</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soy un cloud engineer, trabajo en google</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text Language Predicted Language\n",
       "0              Do you want tortilla for dinner?  English            English\n",
       "1  Este es un ejemplo de software developement.  Spanish            Spanish\n",
       "2      Soy un cloud engineer, trabajo en google  Spanish            Spanish"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentences = [\n",
    "    {\"Text\": \"Do you want tortilla for dinner?\", \"Language\": \"English\"},\n",
    "    {\"Text\": \"Este es un ejemplo de software developement.\", \"Language\": \"Spanish\"},\n",
    "    {\"Text\": \"Soy un cloud engineer, trabajo en google\", \"Language\": \"Spanish\"}\n",
    "]\n",
    "\n",
    "# Convirtamos las frases de ejemplo en un dataframe\n",
    "sample_df = pd.DataFrame(sample_sentences)\n",
    "\n",
    "# Tokenizamos las frases de ejemplo\n",
    "sample_dataset = Dataset.from_pandas(sample_df)\n",
    "sample_preprocessed_dataset = sample_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Efectuemos las predicciones\n",
    "sample_predictions = trainer.predict(sample_preprocessed_dataset)\n",
    "sample_preds = np.argmax(sample_predictions.predictions, axis=1)\n",
    "sample_df[\"Predicted Language\"] = label_encoder.inverse_transform(sample_preds)\n",
    "\n",
    "print(\"Resultados de las predicciones en las frases de ejemplo:\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos reentrenado un modelo ya capacitado para realizar clasificación de idiomas con nuestros datos, que contenían solo español e inglés. Esperábamos obtener resultados muy buenos. Dado que esta no es la parte central del proyecto, utilizaremos este modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
