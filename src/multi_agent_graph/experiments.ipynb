{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "MODELS_LOCATION = os.path.join(current_dir.parent, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_7488\\1967587763.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have set `args.eval_strategy` to IntervalStrategy.EPOCH but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 25\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Inizializzare il Trainer (utilizzando gli stessi argomenti che hai usato per l'addestramento)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     15\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Funzione per fare la predizione\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_sentence\u001b[39m(sentence):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Creare un dataset con la frase di esempio\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:442\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `batch_eval_metrics`, your `compute_metrics` function must take a `compute_result`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m boolean argument which will be triggered after the last batch of the eval set to signal that the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m summary statistics should be returned by the function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    440\u001b[0m         )\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have set `args.eval_strategy` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39meval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mload_best_model_at_end:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmetric_for_best_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: You have set `args.eval_strategy` to IntervalStrategy.EPOCH but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "# Percorso del modello e tokenizer salvati\n",
    "model_directory = os.path.join(MODELS_LOCATION, 'disease_classification_spanish_nlp')\n",
    "\n",
    "# Caricare il tokenizer e il modello\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_directory)\n",
    "\n",
    "# Inizializzare il Trainer (utilizzando gli stessi argomenti che hai usato per l'addestramento)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,              # Tasa de aprendizaje: se ha probado 5e-6, 1e-5, 5e-5 y 2e-5\n",
    "    per_device_train_batch_size=32,   # Tama√±o del batch para entrenamiento: se ha probado 8, 16, 32, 64\n",
    "    per_device_eval_batch_size=32,    # Tama√±o del batch para evaluaci√≥n\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.3,               # Decaimiento de peso: hemos probado 0.01, 0.1, 0.2 e 0.3 e 0.4 y este era el mejor\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Funzione per fare la predizione\n",
    "def predict_sentence(sentence):\n",
    "    # Creare un dataset con la frase di esempio\n",
    "    sample_df = [{\"S√≠ntomas\": sentence, \"Enfermedad\": \"\"}]  # La colonna 'Enfermedad' non √® necessaria per la predizione\n",
    "    sample_dataset = Dataset.from_pandas(pd.DataFrame(sample_df))\n",
    "\n",
    "    # Preprocessare i dati\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples['S√≠ntomas'], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "    sample_preprocessed_dataset = sample_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    # Fare la predizione\n",
    "    predictions = trainer.predict(sample_preprocessed_dataset)\n",
    "\n",
    "    # Prendere la classe predetta\n",
    "    predicted_class = np.argmax(predictions.predictions, axis=1)\n",
    "    \n",
    "    return predicted_class[0]\n",
    "\n",
    "# Esempio di frase per la predizione\n",
    "sentence = \"Mi sento stanco e debole tutto il tempo\"\n",
    "predicted_class = predict_sentence(sentence)\n",
    "\n",
    "prediction_mapping = {0: 'Anemia',\n",
    "                        1: 'Diabetes', \n",
    "                        2: 'Talasemia', \n",
    "                        3: 'Trombosis'}\n",
    "\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glucose,Cholesterol,Hemoglobin,Platelets,White Blood Cells,Red Blood Cells,Hematocrit,Mean Corpuscular Volume,Mean Corpuscular Hemoglobin,Mean Corpuscular Hemoglobin Concentration,Insulin,BMI,Systolic Blood Pressure,Diastolic Blood Pressure,Triglycerides,HbA1c,LDL Cholesterol,HDL Cholesterol,ALT,AST,Heart Rate,Creatinine,Troponin,C-reactive Protein,Disease\n",
    "0.7395967125241718,0.6501983879188533,0.7136309861450383,0.8684912414028263,0.6874330284922628,0.5298953992757882,0.2900059089747371,0.6310450180806368,0.0013278578317175,0.7958288704767718,0.0341291220877673,0.0717741989094826,0.1855955968893292,0.0714546096693165,0.6534723763050316,0.5026647785611607,0.2155602381567172,0.5129405631422954,0.0641873469615352,0.610826509528389,0.9394848536044538,0.0955115282493801,0.4659569674775698,0.7692300746279673,Healthy\n",
    "\n",
    " Prendi il precedente dataset che contiene i risultati di un'analisi del sangue, creami un testo IN inglese che sia un'analisi del sangue che contenga i precedenti valori e altre frasi e informazioni precedenti e successive inventate da te per favore. Non fare tabelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['Glucose', 'Cholesterol', 'Hemoglobin', 'Platelets', 'White Blood Cells', 'Red Blood Cells', 'Hematocrit', 'Mean Corpuscular Volume', 'Mean Corpuscular Hemoglobin', 'Mean Corpuscular Hemoglobin Concentration', 'Insulin', 'BMI', 'Systolic Blood Pressure', 'Diastolic Blood Pressure', 'Triglycerides', 'HbA1c', 'LDL Cholesterol', 'HDL Cholesterol', 'ALT', 'AST', 'Heart Rate', 'Creatinine', 'Troponin', 'C-reactive Protein'] \n",
    "b = ['Red Blood Cells', 'Mean Corpuscular Hemoglobin', 'LDL Cholesterol', 'Hemoglobin', 'AST', 'ALT', 'Heart Rate', 'Platelets', 'Hematocrit', 'Triglycerides', 'Troponin', 'Mean Corpuscular Volume', 'C-reactive Protein', 'Mean Corpuscular Hemoglobin Concentration', 'Systolic Blood Pressure', 'Glucose', 'White Blood Cells', 'Creatinine', 'HbA1c', 'Insulin', 'BMI', 'Diastolic Blood Pressure', 'HDL Cholesterol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 24, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a)==sorted(b), len(a), len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "miei = ['Glucose', 'Cholesterol', 'Hemoglobin', 'Platelets', 'White Blood Cells', 'Red Blood Cells', 'Hematocrit', 'Mean Corpuscular Volume', 'Mean Corpuscular Hemoglobin', 'Mean Corpuscular Hemoglobin Concentration', 'Insulin', 'BMI', 'Systolic Blood Pressure', 'Diastolic Blood Pressure', 'Triglycerides', 'HbA1c', 'LDL Cholesterol', 'HDL Cholesterol', 'ALT', 'AST', 'Heart Rate', 'Creatinine', 'Troponin', 'C-reactive Protein']\n",
    "miei = sorted(miei)\n",
    "suoi = [\"HDL Cholesterol\", \"White Blood Cells\", \"ALT\", \"Cholesterol\", \"Creatinine\", \"Hemoglobin\", \"Heart Rate\", \"Systolic Blood Pressure\", \"Troponin\", \"Insulin\", \"AST\", \"BMI\", \"Platelets\", \"Red Blood Cells\", \"Mean Corpuscular Hemoglobin Concentration\", \"C-reactive Protein\", \"Hematocrit\", \"Mean Corpuscular Hemoglobin\", \"Glucose\", \"Diastolic Blood Pressure\", \"LDL Cholesterol\", \"Mean Corpuscular Volume\", \"Triglycerides\", \"HbA1c\"]\n",
    "suoi = sorted(suoi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
